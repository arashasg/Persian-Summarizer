{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ParsBERT-sum.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## This script can be used for traning a summarization model based on BERT2BERT architecture"
      ],
      "metadata": {
        "id": "Gt8GJIe3_lDg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_tOSEWw_Asg"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python ../Src/BERT2BERT/run_summarization.py \\\n",
        "--model_name_or_path HooshvareLab/bert-base-parsbert-ner-uncased \\\n",
        "--pad_to_max_length True \\\n",
        "--do_train False \\\n",
        "--do_eval \\\n",
        "--early_stopping_patience 2 \\\n",
        "--do_predict \\\n",
        "--load_best_model_at_end \\\n",
        "--num_beams 4 \\\n",
        "--max_source_length 512 \\\n",
        "--max_target_length 128 \\\n",
        "--save_strategy epoch \\\n",
        "--evaluation_strategy epoch \\\n",
        "--train_file ./data/train.csv \\\n",
        "--validation_file ./data/val.csv \\\n",
        "--test_file ./data/test.csv \\\n",
        "--output_dir ./outputs \\\n",
        "--logging_dir ./outputs/logs \\\n",
        "--predict_with_generate \\\n",
        "--text_column News \\\n",
        "--summary_column Summarization \\\n",
        "--preprocessing_num_workers 1 \\\n",
        "--dataloader_num_workers 1 \\\n",
        "--gradient_accumulation_steps 1 \\\n",
        "--per_device_train_batch_size 4 \\\n",
        "--per_device_train_batch_size 4 \\\n",
        "--num_train_epochs 1 \\\n",
        "--logging_steps 500 \\\n",
        "--warmup_steps 1000"
      ]
    }
  ]
}